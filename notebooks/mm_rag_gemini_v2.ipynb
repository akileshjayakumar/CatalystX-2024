{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "vertexai.init(project=os.getenv(\"PROJECT\"), location=os.getenv(\"LOCATION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "data_url = \"https://storage.googleapis.com/benchmarks-artifacts/langchain-docs-benchmarking/cj.zip\"\n",
    "result = requests.get(data_url)\n",
    "filename = \"cj.zip\"\n",
    "with open(filename, \"wb\") as file:\n",
    "   file.write(result.content)\n",
    "\n",
    "with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "   zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./cj/cj.pdf\")\n",
    "docs = loader.load()\n",
    "tables = []\n",
    "texts = [d.page_content for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 1/21Clouded Judgement 11.10.23 - OpenAI\\nUpdates + Datadog Gives the All-Clear?\\nJAMIN BALL\\nNOV 10, 2023\\n2 Share\\nEvery week I’ll provide updates on the latest trends in cloud so\\x00ware companies. Follow along to\\nstay up to date!\\nOpen AI U pdates\\nOpenAI had their big developer day this week, and I wanted to call out two key announcements\\n(and trends): increasing context windows and decreasing costs.\\nWhen I think about the monetization of AI (and which “layers” monetize \\x00rst) I’ve always\\nthought it would follow the below order, with each layer lagging the one that comes before it.\\n1. Raw silicon (chips like Nvidia bought in large quantities to build out infra to service\\nupcoming demand).\\n2. Model providers (OpenAI, Anthropic, etc as companies start building out AI).\\n35\\nType your email... Subscribe', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 2/213. Hyperscalers (AWS, Azure, GC P as companies look for cloud GPUs who aren’t building out\\ntheir own data centers)\\n4. Infra (Data layer, orchestration, monitoring, ops, etc)\\n5. Durable Applications\\nWe’ve clearly well underway of the \\x00rst 3 layers monetizing. Just starting the fourth layer, with\\nthe \\x00\\x00h layer showing up in some pockets, but not really widespread monetization (and I should\\nclarify - scalable monetization). The caveat is important - I’ve heard of a well known company\\nthat had an o\\x00shore team handling lots of manual customer work (ie responses). And this\\n“product” had a ~50% g ross margin. When they started using large language models from\\nOpenAI, the gross margin on the same product went to -100%! (y es, that’s negative 100%) . While\\nthe product was “monetizing” I wouldn’t count it as scalable monetization.\\nWe haven’t quite yet cracked AI used in production in widespread fashion. There are many\\nlimiters here - data security and compliance are big ones. But even more important right now is\\ncost. At the end of the day, these large language models are quite expensive! And as a vendor\\nusing them, you can either pass through the costs to your end customer (to maintain your gross\\nmargins), or eat the costs and lower your gross margins (because the customer isn’t willing to pay\\nthe incremental cost for incremental functionality brought about by AI), and hope the model\\nproviders lower their costs in the future. It seems like every company has been experimenting.\\nSaying things like “just build out all the AI functionality now and then we’ll evaluate if\\ncustomers will pay for it.” Now that we’re getting through this initial wave of experimentation\\nand AI buildout, there’s quite a bit of sticker shock when the OpenAI bills come due! People are\\nlooking to build in model portability to enable them to switch to lower cost models (or open\\nsource).', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 3/21This brings me back to the initial point - the two announcements from OpenAI I want to\\nhighlight here.\\n1. Context length: Context window of GPT 4 Turbo went from 8k tokens to 128k  tokens (think\\nof this as ~300 p ages of text worth of input). This means what you can put into a prompt just\\nwent up dramatically\\n2. Costs decreasing: GP T 4 Turbo is 3x cheaper for input tokens (think of this as roughly the\\nlength of the prompt) and 2x cheaper for output tokens. This equates to $0.01 p er 1k input\\ntokens, and $0.03 p er 1k output tokens. On a blended basis, GP T 4 Turbo is roughly 2.5-3x\\ncheaper than GPT 4.\\nThe cost decrease is very meaningful - it’s lowers the barrier to experiment with AI, and also\\nlowers the barrier for these AI functionalities to be pushed into production (because vendors\\ndon’t have to increase price nearly as much). Also - As Moin pointed out on Twitter / X, as\\ncontext windows increase the need for task / domain-speci\\x00c models (or \\x00ne-tuned models)\\ndecreases. The counter argument to this is will we be able to \\x00nd enough high quality long\\ncontext training data. Either way - it’s clear these models are becoming cheaper and more\\ne\\x00ective, which is an exciting future for AI! I think we’re about to see an explosion of good\\nbusiness model AI applications in the near future. 2024 w ill be the year of AI applications!\\nDatadog G ives So\\x00w are t he A ll C lear?\\nThis week so\\x00ware stocks shot up on Tuesday, largely a result of Datadog’s quarterly earnings.\\nDatadog in particular was up ~30%. S o what happened? They made a number of comments about\\noptimizations easing up, and the worst being behind us. Here are some quotes:', \"11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 4/21“It looks like we've hit an in\\x00ection point. It looks like there's a lot less overhang now in\\nterms of what needs to be optimized or could be optimized by customers. It looks like\\nalso optimization is less intense and less widespread across the customer base.”\\n“We had a very healthy start to Q4 in October...the trends we see in early Q4 are stronger\\nthan they've been for the past year.”\\n“As we look at our overall customer activity, we continue to see customers optimizing\\nbut with less impact than we experienced in Q2, contributing to our usage growth with\\nexisting customers improving in Q3 relative to Q2.”\\n“As a reminder, last quarter, we discussed a cohort of customers who began optimizing\\nabout a year ago and we said that they appear to stabilize their users growth at the end of\\nQ2. That trend has held for the past several months with that cohorts usage remaining\\nstable throughout Q3.”\\nDatadog was one of the \\x00rst companies to really highlight an improving macro environment.\\nAnd even more important, they called out a great month of October (\\x00rst month of Q4 for them).\\nSo how do we contrast their positive commentary, with largely neutral commentary from the rest\\nof the so\\x00ware universe? Most likely Datadog is seeing trends more unique to their own\\nbusiness. As the market puts a greater emphasis on bundled platforms today vs point solutions,\\nthey appear to be an incremental winner of market share. Best of breed platforms (with more of a\\nusage based model) will recover \\x00rst (in terms of revenue growth recovery). Datadog appears to\\nbe in that bucket and recovering \\x00rst. This doesn’t mean the rest of the so\\x00ware universe will\\nfollow suite. There will be many “pretenders” who never recover and \\x00nd themselves bundled\\ninto oblivion. However, the positive commentary from Datadog is the \\x00rst sign that we’re\", '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 5/21starting to turn a corner. So while the rest of the so\\x00ware universe may not be at that corner\\ntoday, we’re starting to see the light at the end of the tunnel.\\nQuarterly R ep orts Summary\\nTop 10 EV / N TM  R even ue M ultiples\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 6/21Top 10 W eek ly Share P rice M oveme nt\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 7/21Update o n M ultiples\\nSaaS businesses are generally valued on a multiple of their revenue - in most cases the projected\\nrevenue for the next 12 m onths. Revenue multiples are a shorthand valuation framework. Given\\nmost so\\x00ware companies are not pro\\x00table, or not generating meaningful FCF, it’s the only\\nmetric to compare the entire industry against. Even a DCF is riddled with long term\\nassumptions. The promise of SaaS is that growth in the early years leads to pro\\x00ts in the mature\\nyears. Multiples shown below are calculated by taking the Enterprise Value (market cap + debt -\\ncash) / NTM revenue.\\nOverall Stats:\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 8/21Overall Median: 5.0x\\nTop 5 M edian: 14.5x\\n10Y: 4.6%\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 9/21Bucketed by Growth. In the buckets below I consider high growth >30% p rojected NTM growth,\\nmid growth 15%-30% a nd low growth <15%\\nHigh Growth Median: 11.8x\\nMid Growth Median: 7.4x\\nLow Growth Median: 3.9x\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 10/21\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 11/21EV / N TM  R ev / N TM  G rowth\\nThe below chart shows the EV / NTM revenue multiple divided by NTM consensus growth\\nexpectations. So a company trading at 20x NTM revenue that is projected to grow 100% w ould be\\ntrading at 0.2x . The goal of this graph is to show how relatively cheap / expensive each stock is\\nrelative to their growth expectations\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 12/21\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 13/21EV / N TM  FCF\\nThe line chart shows the median of all companies with a FCF multiple >0x and <100x . I created\\nthis subset to show companies where FCF is a relevant valuation metric.\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 14/21Companies with negative NTM FCF are not listed on the chart\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 15/21Sca tter Plot of EV / N TM  R ev M ultiple vs N TM  R ev G rowth\\nHow correlated is growth to valuation multiple?\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 16/21Operating M etrics\\nMedian NTM growth rate: 15%\\nMedian LTM growth rate: 21%\\nMedian Gross Margin: 75%\\nMedian Operating Margin (18%)\\nMedian FCF Margin: 8%\\nMedian Net Retention: 114%\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 17/21Median CAC Payback: 35 m onths\\nMedian S&M % Re venue: 42%\\nMedian R&D % Re venue: 26%\\nMedian G&A % Re venue: 17%\\nComps O utput\\nRule of 40 s hows rev growth + FCF margin (both LTM and NTM for growth + margins). FCF\\ncalculated as Cash Flow from Operations - Capital Expenditures\\nGM Adjusted Payback is calculated as: (Previous Q S&M) / (N et New ARR i n Q x Gross Margin) x\\n12 . I t shows the number of months it takes for a SaaS business to payback their fully burdened\\nCAC on a gross pro\\x00t basis. Most public companies don’t report net new ARR, s o I’m taking an\\nimplied ARR m etric (quarterly subscription revenue x 4). Net new ARR i s simply the ARR o f the\\ncurrent quarter, minus the ARR o f the previous quarter. Companies that do not disclose\\nsubscription rev have been le\\x00 out of the analysis and are listed as NA.', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 18/21\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 19/21Sources used in this post include Bloomberg, Pitchbook and company \\x00lings\\nThe information presented in this newsletter is the opinion of the author and does not\\nnecessarily re\\x00ect the view of any other person or entity,\\xa0including Altimeter Capital\\nManagement, LP (\"Altimeter\").\\xa0 The information provided is believed to be from reliable sources\\nbut no liability is accepted for any inaccuracies.\\xa0 This is for information purposes and should not\\nbe construed as an investment recommendation.\\xa0 Past performance is no guarantee of future\\nperformance.\\xa0 Altimeter is an investment adviser registered with the U.S. Securities and\\nExchange Commission. Registration does not imply a certain level of skill or training.\\xa0\\nThis post and the i nformation presented are intended for informational purposes only.\\xa0The\\nviews expressed herein are the author’s alone and do not constitute an o\\x00er to sell, or a\\nrecommendation to purchase, or a solicitation of an o\\x00er to buy, any security, nor a\\nrecommendation for any investment product or service. While certain information contained\\nherein has been obtained from sources believed to be reliable, neither the author nor any of his\\nemployers or their a\\x00liates have independently veri\\x00ed this information, and its accuracy and\\ncompleteness cannot be guaranteed. Accordingly, no representation or warranty, express or\\n', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 20/21implied, is made as to, and no reliance should be placed on, the fairness, accuracy, timeliness or\\ncompleteness of this information. The author and all employers and their a\\x00liated persons\\nassume no liability for this information and no obligation to update the information or analysis\\ncontained herein in the future.\\n35 Likes·3 Restacks\\n2 CommentsType your email... Subscribe\\nWrite a comment...\\nStefan WaldhauserWrites High Growth InvestingNov 12\\nThank you for your interesting thoughts regarding the monetization layers of AI. Really inspiring!\\nLIKEREPLYSHARE\\nMatthew HarrisWrites AgoraNov 10\\nGood stuff as always. Your point about the reduced costs per token is interesting and hopefully\\nallows companies to experiment with AI more in their workflows\\nLIKEREPLYSHARE', '11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 21/21© 2023Jamin Ball\\xa0∙\\xa0Privacy ∙ Terms ∙ Collection notice\\nSubstackis the home for great writing']\n"
     ]
    }
   ],
   "source": [
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11/14/23, 8:35 PM Clouded Judgement 11.10.23 - by Jamin Ball\\nhttps://cloudedjudgement.substack.com/p/clouded-judgement-111023 1/21Clouded Judgement 11.10.23 - OpenAI\\nUpdates + Datadog Gives the All-Clear?\\nJAMIN BALL\\nNOV 10, 2023\\n2 Share\\nEvery week I’ll provide updates on the latest trends in cloud so\\x00ware companies. Follow along to\\nstay up to date!\\nOpen AI U pdates\\nOpenAI had their big developer day this week, and I wanted to call out two key announcements\\n(and trends): increasing context windows and decreasing costs.\\nWhen I think about the monetization of AI (and which “layers” monetize \\x00rst) I’ve always\\nthought it would follow the below order, with each layer lagging the one that comes before it.\\n1. Raw silicon (chips like Nvidia bought in large quantities to build out infra to service\\nupcoming demand).\\n2. Model providers (OpenAI, Anthropic, etc as companies start building out AI).\\n35\\nType your email... Subscribe'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.generativeai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableLambda\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgenai\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.generativeai'"
     ]
    }
   ],
   "source": [
    "from langchain_google_vertexai import VertexAI, ChatVertexAI, VertexAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import os\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summaries of text elements\n",
    "def generate_text_summaries(texts, tables, summarize_texts=False):\n",
    "    \"\"\"\n",
    "    Summarize text elements\n",
    "    texts: List of str\n",
    "    tables: List of str\n",
    "    summarize_texts: Bool to summarize texts\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    Give a concise summary of the table or text that is well optimized for retrieval. Table or text: {element} \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_text)\n",
    "    \n",
    "    # Create the model\n",
    "    generation_config = {\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 40,\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    }\n",
    "\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-pro-exp-0827\",\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "\n",
    "    chat_session = model.start_chat(\n",
    "        history=[]\n",
    "    )\n",
    "\n",
    "    summarize_chain = {\n",
    "        \"element\": lambda x: x\n",
    "    } | prompt | RunnableLambda(lambda x: chat_session.send_message(x).content) | StrOutputParser()\n",
    "\n",
    "    # Initialize empty summaries\n",
    "    text_summaries = []\n",
    "    table_summaries = []\n",
    "\n",
    "    # Apply to text if texts are provided and summarization is requested\n",
    "    if texts and summarize_texts:\n",
    "        text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 1})\n",
    "    elif texts:\n",
    "        text_summaries = texts\n",
    "\n",
    "    # Apply to tables if tables are provided\n",
    "    if tables:\n",
    "        table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 1})\n",
    "\n",
    "    return text_summaries, table_summaries\n",
    "\n",
    "\n",
    "# Get text summaries\n",
    "text_summaries, table_summaries = generate_text_summaries(\n",
    "    texts, tables, summarize_texts=True\n",
    ")\n",
    "\n",
    "text_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "   \"\"\"Getting the base64 string\"\"\"\n",
    "   with open(image_path, \"rb\") as image_file:\n",
    "       return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def image_summarize(img_base64, prompt):\n",
    "   \"\"\"Make image summary\"\"\"\n",
    "   model = ChatVertexAI(model_name=\"gemini-pro-vision\", max_output_tokens=1024)\n",
    "\n",
    "   msg = model(\n",
    "       [\n",
    "           HumanMessage(\n",
    "               content=[\n",
    "                   {\"type\": \"text\", \"text\": prompt},\n",
    "                   {\n",
    "                       \"type\": \"image_url\",\n",
    "                       \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"},\n",
    "                   },\n",
    "               ]\n",
    "           )\n",
    "       ]\n",
    "   )\n",
    "   return msg.content\n",
    "\n",
    "\n",
    "def generate_img_summaries(path):\n",
    "   \"\"\"\n",
    "   Generate summaries and base64 encoded strings for images\n",
    "   path: Path to list of .jpg files extracted by Unstructured\n",
    "   \"\"\"\n",
    "\n",
    "   # Store base64 encoded images\n",
    "   img_base64_list = []\n",
    "\n",
    "   # Store image summaries\n",
    "   image_summaries = []\n",
    "\n",
    "   # Prompt\n",
    "   prompt = \"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
    "   These summaries will be embedded and used to retrieve the raw image. \\\n",
    "   Give a concise summary of the image that is well optimized for retrieval.\"\"\"\n",
    "\n",
    "   # Apply to images\n",
    "   for img_file in sorted(os.listdir(path)):\n",
    "       if img_file.endswith(\".jpg\"):\n",
    "           img_path = os.path.join(path, img_file)\n",
    "           base64_image = encode_image(img_path)\n",
    "           img_base64_list.append(base64_image)\n",
    "           image_summaries.append(image_summarize(base64_image, prompt))\n",
    "\n",
    "   return img_base64_list, image_summaries\n",
    "\n",
    "\n",
    "# Image summaries\n",
    "img_base64_list, image_summaries = generate_img_summaries(\"./cj\")\n",
    "\n",
    "len(img_base64_list)\n",
    "\n",
    "len(image_summaries)\n",
    "\n",
    "image_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_vector_retriever(\n",
    "    vectorstore, text_summaries, texts, table_summaries, tables, image_summaries, images\n",
    "):\n",
    "   \"\"\"\n",
    "   Create retriever that indexes summaries, but returns raw images or texts\n",
    "   \"\"\"\n",
    "\n",
    "   # Initialize the storage layer\n",
    "   store = InMemoryStore()\n",
    "   id_key = \"doc_id\"\n",
    "\n",
    "   # Create the multi-vector retriever\n",
    "   retriever = MultiVectorRetriever(\n",
    "       vectorstore=vectorstore,\n",
    "       docstore=store,\n",
    "       id_key=id_key,\n",
    "   )\n",
    "\n",
    "   # Helper function to add documents to the vectorstore and docstore\n",
    "   def add_documents(retriever, doc_summaries, doc_contents):\n",
    "       doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
    "       summary_docs = [\n",
    "           Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "           for i, s in enumerate(doc_summaries)\n",
    "       ]\n",
    "       retriever.vectorstore.add_documents(summary_docs)\n",
    "       retriever.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
    "\n",
    "   # Add texts, tables, and images\n",
    "   # Check that text_summaries is not empty before adding\n",
    "   if text_summaries:\n",
    "       add_documents(retriever, text_summaries, texts)\n",
    "   # Check that table_summaries is not empty before adding\n",
    "   if table_summaries:\n",
    "       add_documents(retriever, table_summaries, tables)\n",
    "   # Check that image_summaries is not empty before adding\n",
    "   if image_summaries:\n",
    "       add_documents(retriever, image_summaries, images)\n",
    "\n",
    "   return retriever\n",
    "\n",
    "\n",
    "# The vectorstore to use to index the summaries\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"mm_rag_cj_blog\",\n",
    "    embedding_function=VertexAIEmbeddings(\n",
    "        model_name=\"textembedding-gecko@latest\"),\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever_multi_vector_img = create_multi_vector_retriever(\n",
    "    vectorstore,\n",
    "    text_summaries,\n",
    "    texts,\n",
    "    table_summaries,\n",
    "    tables,\n",
    "    image_summaries,\n",
    "    img_base64_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "   \"\"\"Disply base64 encoded string as image\"\"\"\n",
    "   # Create an HTML img tag with the base64 string as the source\n",
    "   image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "   # Display the image by rendering the HTML\n",
    "   display(HTML(image_html))\n",
    "\n",
    "\n",
    "def looks_like_base64(sb):\n",
    "   \"\"\"Check if the string looks like base64\"\"\"\n",
    "   return re.match(\"^[A-Za-z0-9+/]+[=]{0,2}$\", sb) is not None\n",
    "\n",
    "\n",
    "def is_image_data(b64data):\n",
    "   \"\"\"\n",
    "   Check if the base64 data is an image by looking at the start of the data\n",
    "   \"\"\"\n",
    "   image_signatures = {\n",
    "       b\"\\xFF\\xD8\\xFF\": \"jpg\",\n",
    "       b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\": \"png\",\n",
    "       b\"\\x47\\x49\\x46\\x38\": \"gif\",\n",
    "       b\"\\x52\\x49\\x46\\x46\": \"webp\",\n",
    "   }\n",
    "   try:\n",
    "       # Decode and get the first 8 bytes\n",
    "       header = base64.b64decode(b64data)[:8]\n",
    "       for sig, format in image_signatures.items():\n",
    "           if header.startswith(sig):\n",
    "               return True\n",
    "       return False\n",
    "   except Exception:\n",
    "       return False\n",
    "\n",
    "\n",
    "def resize_base64_image(base64_string, size=(128, 128)):\n",
    "   \"\"\"\n",
    "   Resize an image encoded as a Base64 string\n",
    "   \"\"\"\n",
    "   # Decode the Base64 string\n",
    "   img_data = base64.b64decode(base64_string)\n",
    "   img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "   # Resize the image\n",
    "   resized_img = img.resize(size, Image.LANCZOS)\n",
    "\n",
    "   # Save the resized image to a bytes buffer\n",
    "   buffered = io.BytesIO()\n",
    "   resized_img.save(buffered, format=img.format)\n",
    "\n",
    "   # Encode the resized image to Base64\n",
    "   return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "   \"\"\"\n",
    "   Split base64-encoded images and texts\n",
    "   \"\"\"\n",
    "   b64_images = []\n",
    "   texts = []\n",
    "   for doc in docs:\n",
    "       # Check if the document is of type Document and extract page_content if so\n",
    "       if isinstance(doc, Document):\n",
    "           doc = doc.page_content\n",
    "       if looks_like_base64(doc) and is_image_data(doc):\n",
    "           doc = resize_base64_image(doc, size=(1300, 600))\n",
    "           b64_images.append(doc)\n",
    "       else:\n",
    "           texts.append(doc)\n",
    "   if len(b64_images) > 0:\n",
    "       return {\"images\": b64_images[:1], \"texts\": []}\n",
    "   return {\"images\": b64_images, \"texts\": texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_prompt_func(data_dict):\n",
    "   \"\"\"\n",
    "   Join the context into a single string\n",
    "   \"\"\"\n",
    "   formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
    "   messages = []\n",
    "\n",
    "   # Adding the text for analysis\n",
    "   text_message = {\n",
    "       \"type\": \"text\",\n",
    "       \"text\": (\n",
    "           \"You are financial analyst tasking with providing investment advice.\\n\"\n",
    "           \"You will be given a mixed of text, tables, and image(s) usually of charts or graphs.\\n\"\n",
    "           \"Use this information to provide investment advice related to the user question. \\n\"\n",
    "           f\"User-provided question: {data_dict['question']}\\n\\n\"\n",
    "           \"Text and / or tables:\\n\"\n",
    "           f\"{formatted_texts}\"\n",
    "       ),\n",
    "   }\n",
    "   messages.append(text_message)\n",
    "   # Adding image(s) to the messages if present\n",
    "   if data_dict[\"context\"][\"images\"]:\n",
    "       for image in data_dict[\"context\"][\"images\"]:\n",
    "           image_message = {\n",
    "               \"type\": \"image_url\",\n",
    "               \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "           }\n",
    "           messages.append(image_message)\n",
    "   return [HumanMessage(content=messages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_modal_rag_chain(retriever):\n",
    "   \"\"\"\n",
    "   Multi-modal RAG chain\n",
    "   \"\"\"\n",
    "\n",
    "   # Multi-modal LLM\n",
    "   model = ChatVertexAI(\n",
    "       temperature=0, model_name=\"gemini-pro-vision\", max_output_tokens=1024\n",
    "   )\n",
    "\n",
    "   # RAG pipeline\n",
    "   chain = (\n",
    "       {\n",
    "           \"context\": retriever | RunnableLambda(split_image_text_types),\n",
    "           \"question\": RunnablePassthrough(),\n",
    "       }\n",
    "       | RunnableLambda(img_prompt_func)\n",
    "       | model\n",
    "       | StrOutputParser()\n",
    "   )\n",
    "\n",
    "   return chain\n",
    "\n",
    "\n",
    "# Create RAG chain\n",
    "chain_multimodal_rag = multi_modal_rag_chain(retriever_multi_vector_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
